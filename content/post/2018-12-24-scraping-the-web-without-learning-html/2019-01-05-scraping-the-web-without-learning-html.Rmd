---
title: Scraping the Web without Learning HTML
author: Letisha Smith
date: '2019-01-05'
categories:
  - Tutorial
slug: scraping-the-web-without-learning-html
featuredImage:
  caption: ''
  focal_point: ''
---

Last year was a whirlwind full of exciting opportunities to travel and share my dual passions of food and statistics. When I resolved to eat healthier, my inner quant couldn’t resist the opportunity of using data to better achieve this goal. Therefore, I applied unsupervised machine learning to ease meal prep by grouping together recipes that shared similar ingredients. My data came from ingredients used in dishes uploaded to allrecipes.com, which as of May 2018 contained over 14,000 main meal dishes.

So, there was a lot of interest in how I collected this data--like the following text message:

![](/post/2018-12-24-scraping-the-web-without-learning-html_files/01-text.png){width=50% height=50%}

This article is me keeping true to my word, though I am actually dividing the topic into more than one post. Here will cover web scraping essentials with the rvest package in R, then I will follow-up with a post on using functional programming to scrape multiple pages.

### What is web scraping
A website is essentially a collection of archived information--which incidentally makes it a rich data source.  Headlines, comments, and metrics, like the weather, are stored on a site and can be gathered to respectively get a sense of newsworthy topics, opinions, and trends over time. 

This data must be extracted from the site into an analyzable format. Rather than copy and paste information, web scraping can be used to directly accumulate content from a website. 

### How does web scraping work
A webpage can be uniquely identified by its URL (Uniform Resource Locator) , which is also associated with an HTML (Hypertext Markup Language) file. HTML files provide guidelines for producing content on a webpage, and you can always view the HTML document used to generate a webpage by right-clicking and selecting `View Page Source`. 

![](/post/2018-12-24-scraping-the-web-without-learning-html_files/02-main_dish.png) 

![](/post/2018-12-24-scraping-the-web-without-learning-html_files/03-view_source.png)

If you are using a Google Chrome web browser, then a right-click and selection of `Inspect` opens the HTML document in the same window as the webpage. Hovering over the HTML will highlight corresponding portions on the page. If you desire to highlight a more granular piece of information on the web page, you can attempt to accomplish this by hovering over a line of HTML and clicking on the left triangular icon to drill down into the text.

![](/post/2018-12-24-scraping-the-web-without-learning-html_files/04-inspect.png)

You don’t need to be fluent in HTML in order to webscrape. Just know that the information you want to analyze on a site is stored in an html file, and web scraping can be used to collect this information. 

### Using patterns to extract information
HTML helps to organize a page by indicating how text should be displayed--for instance in a header, list, or certain division of the page. Categorically similar information tends to be visually alike, making a website easier to navigate. For example, recipe ingredients may be presented as a list and stylized with a font or color to be distinguished from recipe instructions. Stylistic patterns designed to ease user experience can be exploited to easily detect and collect information of interest from a website.

While HTML is responsible for structuring content on a webpage, CSS (Cascading Style Sheets) controls site aesthetics, like color scheme and fonts. Therefore, extracting categorically similar information from a site is easier if you know the HTML and CSS used to format the content.

* While HTML is responsible for structuring content on a webpage, CSS (Cascading Style Sheets) controls site aesthetics, like color scheme and fonts. Therefore, extracting categorically similar information from a site is **_easier_** if you know the HTML and CSS used to format the content.

You can figure out the HTML and CSS specifications for displaying content with the [Google Chrome](https://www.google.com/chrome/) plugin Selector Gadget. Download Google Chrome if you haven’t already, and install the [Selector Gadget Extension](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb).

Here is Selector Gadget’s description of itself:   

> Selector Gadget is an open source Chrome Extension that makes CSS selector generation and discovery on complicated sites a breeze.

After installing the extension, go to any page and launch it. A box will open in the bottom right of the website. Click on a page element that you would like your selector to match (it will turn green). SelectorGadget will then generate a minimal CSS selector for that element, and will highlight (yellow) everything that is matched by the selector. Now click on a highlighted element to remove it from the selector (red), or click on an unhighlighted element to add it to the selector. Through this process of selection and rejection, SelectorGadget helps you come up with the perfect CSS selector for your needs.

After Selector Gadget has been downloaded, click on the Selector Gadget icon in the toolbar to enable it. 

If I wanted to know the HTML/CSS associated with recipe ingredients on allrecipes.com, then clicking on one ingredient highlights it in green and other text with identical HTML/CSS in yellow. 

![](/post/2018-12-24-scraping-the-web-without-learning-html_files/05-selectora.png) 

If the yellow encompasses information that is categorically dissimilar from what you want, then click on the extraneous region and the yellow will turn red. Repeatedly deselect areas until the only information that you want is highlighted in yellow.

![](/post/2018-12-24-scraping-the-web-without-learning-html_files/06-selectorb.png)

The css selector refers to HTML/CSS pattern used to format the text, and it can be found in the bottom right corner of the web browser. The css selector for ingredients is `.recipe-print__container2 ul li`.

### But what does this have to do with R?
R has a package called rvest that is able to scrape data from a webpage if you provide it with the page’s URL and the relevant css selector. 

Download R and preferably the RStudio IDE--if you haven’t already.

Then, install Rvest

```{r, eval=FALSE}
install.packages("rvest")
```

```{r}
# load package
library(rvest)
# load tidyvers to gain access to the pipe %>% function
library(tidyverse)
```
First, store the url to a variable
```{r}
web_address <- "https://www.allrecipes.com/recipe/23600/worlds-best-lasagna/print/?recipeType=Recipe&servings=12&isMetric=false"
```

Please note, that I chose to scrape ingredients from a print view of the recipe and that the URL is for this page. I chose to capture the css selector from this version of allrecipes.com because the print layout is minimal with less irrelevant information. 

To scrape the data we will start with 2 functions   

* read_html() to prepare the html for data extraction  

* html_nodes() to extract data that matches the named css selector   

```{r}
ingredients <- read_html(web_address) %>% 
html_nodes(".recipe-print__container2 ul li")
```
This output is a bit messy because it contains some of the HTML, so one more function is needed to simplify the output  

* html_text() reduces output to only show content

```{r}
read_html(web_address) %>% 
html_nodes(".recipe-print__container2 ul li") %>% 
html_text(trim = T) 
```

Try changing the URL assigned to the web_address variable to see that this css selector can be used to extract ingredient information from any recipe page that is formatted for printing.

Here are a few for you to get started with 
https://www.allrecipes.com/recipe/10813/best-chocolate-chip-cookies/print/?recipeType=Recipe&servings=24&isMetric=false

https://www.allrecipes.com/recipe/15925/creamy-au-gratin-potatoes/print/?recipeType=Recipe&servings=4&isMetric=false

Bon Appetit!

#### Resources

* Web Browsers  
    + https://web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm  
    + https://www.explainthatstuff.com/howthewebworks.html  
    + https://www.w3.org/TR/html401/intro/intro.html    

* HTML    
    + https://www.quora.com/What-are-the-differences-between-HTML-XML-PHP-CSS-and-JavaScript-in-layman%E2%80%99s-terms-Is-it-possible-to-write-a-complex-website-code-successfully-by-using-just-1-of-those-languages  
    + https://www.johnhaydon.com/whats-difference-between-css-html-php/  

* Selector Gadge + Rvest  
    + https://www.rstudio.com/resources/webinars/extracting-data-from-the-web-part-2/  
    + https://blog.rstudio.com/2014/11/24/rvest-easy-web-scraping-with-r/ 
    + https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html 










